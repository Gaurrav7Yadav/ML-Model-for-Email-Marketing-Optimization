# 📌 Step 0: Install required libraries
!pip install pandas scikit-learn seaborn matplotlib xgboost --quiet

# 📌 Step 1: Import libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix
from xgboost import XGBClassifier

# 📌 Step 2: Load the data
from google.colab import files
uploaded = files.upload()

email_df = pd.read_csv('email_table.csv')
opened_df = pd.read_csv('email_opened_table.csv')
clicked_df = pd.read_csv('link_clicked_table.csv')

# 📌 Step 3: Basic metrics
total_sent = email_df.shape[0]
opened = email_df[email_df['email_id'].isin(opened_df['email_id'])].shape[0]
clicked = email_df[email_df['email_id'].isin(clicked_df['email_id'])].shape[0]

print(f"🔹 Open Rate: {opened / total_sent * 100:.2f}%")
print(f"🔹 Click-Through Rate (CTR): {clicked / total_sent * 100:.2f}%")

# 📌 Step 4: Label construction
email_df['opened'] = email_df['email_id'].isin(opened_df['email_id']).astype(int)
email_df['clicked'] = email_df['email_id'].isin(clicked_df['email_id']).astype(int)

# 📌 Step 5: Encode categorical features
features = ['email_text', 'email_version', 'hour', 'weekday', 'user_country', 'user_past_purchases']
X = email_df[features].copy()
y = email_df['clicked']

X['user_past_purchases'] = X['user_past_purchases'].fillna(0)

# Label Encoding for categorical columns
for col in ['email_text', 'email_version', 'weekday', 'user_country']:
    X[col] = LabelEncoder().fit_transform(X[col])

# 📌 Step 6: Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 📌 Step 7: Train the model
model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
model.fit(X_train, y_train)

# 📌 Step 8: Evaluation
y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:, 1]

print("🔍 Classification Report:")
print(classification_report(y_test, y_pred))
print("📈 AUC Score:", roc_auc_score(y_test, y_prob))

# 📌 Step 9: Estimate CTR gain
X['pred_prob'] = model.predict_proba(X)[:, 1]
top_20 = X.sort_values(by='pred_prob', ascending=False).head(int(0.2 * len(X)))
actual_ctr_top20 = email_df.loc[top_20.index, 'clicked'].mean()

print(f"⭐ CTR for top 20% predicted users: {actual_ctr_top20 * 100:.2f}%")
print(f"⭐ Original CTR: {clicked / total_sent * 100:.2f}%")
print(f"📈 Estimated Improvement: {(actual_ctr_top20 - clicked / total_sent) * 100:.2f}%")

# 📌 Step 10: Segment Analysis
segment_cols = ['email_text', 'email_version', 'hour', 'weekday', 'user_country']
for col in segment_cols:
    print(f"\n📊 CTR by {col}:")
    print(email_df.groupby(col)['clicked'].mean().sort_values(ascending=False) * 100)

# 📌 Optional: Heatmap of confusion matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Not Clicked", "Clicked"], yticklabels=["Not Clicked", "Clicked"])
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()
